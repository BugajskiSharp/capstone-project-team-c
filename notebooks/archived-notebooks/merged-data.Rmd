---
title: "EDA"
output: html_document
date: "2025-11-14"
---

Load all libraries (KB)
```{r}
library(here)
library(dplyr)
library(lubridate)
library(readr)
library(tibble)
library(knitr)
library(ggplot2)
```

Import all raw data (KB)
```{r}
weather = read.csv(here("data","raw-data","weather-data.csv"))
airquality = read.csv(here("data","raw-data","air-quality-data.csv"))
boston = read.csv(here("data","raw-data","boston-marathon-data.csv"))
chicago = read.csv(here("data","raw-data","chicago-marathon-data.csv"))
nyc = read.csv(here("data","raw-data","nyc-marathon-data.csv"))
berlin = read.csv(here("data","raw-data","berlin-marathon-data.csv"))
```

Look at the raw datasets (KB)
```{r}
str(boston)
str(berlin)
str(nyc)
str(chicago)
str(weather)
str(airquality)
```
We can see that several of the datasets have varying variable names/formats for year, marathon, gender, and chip_time. We can also see there are variables that are not necessary in several of the marathon datasets.

Standardize all the raw marathon datasets; clean variable names and select necessary variables (KB)
```{r}
boston_clean <- boston %>%
  transmute(
    year = year,
    marathon = "Boston",
    gender = gender,
    chip_time = official_time
  )

berlin_clean <- berlin %>%
  transmute(
    year = YEAR,
    marathon = "Berlin",
    gender = GENDER,
    chip_time = TIME
  )

nyc_clean <- nyc %>%
  transmute(
    year = Year,
    marathon = "NYC",
    gender = Gender,
    chip_time = Finish.Time
  )

chicago_clean <- chicago %>%
  transmute(
    year = Year,
    marathon = "Chicago",
    gender = Gender,
    chip_time = Finish.Time
  )
```

Standardize the raw weather data; format the variables names to make them clean (KB)
```{r}
weather_clean <- weather %>%
  transmute(
    year = Year,
    marathon = Marathon,
    high_temp = High.Temp,
    low_temp = Low.Temp,
    avg_temp = Day.Average.Temp,
    precipitation = Precipitation,
    dew_point = Average.Dew.Point,
    wind_speed = Max.Wind.Speed,
    visibility = Visibility,
    sea_level_pressure = Sea.Level.Pressure
  )
```

Standardize the raw airquality data; format the variables names to make them clean (KB)
```{r}
airquality_clean <- airquality %>%
  transmute(
    year = Year,
    marathon = Marathon,
    aqi = Overall.AQI.Value,
    main_pollutant = Main.Pollutant,
    co = as.numeric(CO),
    ozone = as.numeric(Ozone),
    pm10 = suppressWarnings(as.numeric(PM10)),
    pm25 = as.numeric(PM2.5),
    no2 = as.numeric(NO2)
  )
```

Combine the marathon datasets (KB)
```{r}
# using bind_rows so we can row-wise combine and have data for each runner
marathons_all <- bind_rows(
  boston_clean,
  berlin_clean,
  nyc_clean,
  chicago_clean
)
str(marathons_all)
```
We can see that marathons_all contains the identifying variables (*year, marathon, gender*), and the outcome variable *chip_time*.

Select only years we need (1996 to 2025) (KB)
```{r}
marathons_all <- marathons_all %>%
  filter(year >= 1996 & year <= 2025)

unique(marathons_all$year)
```
We can that the merged marathon data set now contains years from 1996 to 2023, as most dont have data up to 2025.

Chip-Time Cleaning Function (pulled from chatgbt): need chip_seconds to find the average finishing times (KB)
```{r}
# Cleans and standardizes chip-time values by converting Excel-style numeric
# times to HH:MM:SS, trimming and formatting text times, replacing invalid 
# entries with NA, and padding missing leading zeros.

clean_chip_time <- function(x) {

  # Convert numeric Excel-style times to character HH:MM:SS
  x_numeric <- suppressWarnings(as.numeric(x))
  is_fraction <- !is.na(x_numeric) & x_numeric < 1 & x_numeric > 0
  
  x[is_fraction] <- format(
    as.POSIXct("1970-01-01", tz = "UTC") + x_numeric[is_fraction] * 86400,
    "%H:%M:%S"
  )
  
  # Everything else treat as text and clean
  x <- as.character(x)
  x <- trimws(x)
  
  # Replace known invalid strings with NA
  invalid <- c("", "NA", "N/A", "—", "-", "DNF", "DNS", "DQ", "no time", "No Time", "NO TIME")
  x[x %in% invalid] <- NA
  
  # Pad missing zeros (H:MM:SS → HH:MM:SS, etc.)
  x <- gsub("^([0-9]):", "0\\1:", x)
  x <- gsub(":([0-9]):", ":0\\1:", x)
  x <- gsub(":([0-9])$", ":0\\1", x)
  
  return(x)
}
```

Clean chip_time; using `clean_chip_time` function (KB)
```{r}
marathons_all <- marathons_all %>%
  mutate(chip_time_clean = clean_chip_time(chip_time))
```

Convert the cleaned chip_time values (HH:MM:SS) to hms() and period_to_seconds() and gets a new column chip_seconds (KB)
```{r}
marathons_all <- marathons_all %>%
  mutate(
    chip_seconds = suppressWarnings(period_to_seconds(hms(chip_time_clean)))
  )

head(marathons_all)
```
We can see `chip_time` with the original data, `chip_time_clean` with the uniform cleaned data across all marathons, and `chip_seconds` with the total time in seconds. 

Need to see what we want to do with these missing values and where they are coming from (KB)
```{r}
marathons_all %>% 
  summarize(missing_finish_times = sum(is.na(chip_seconds)))

marathons_all %>% 
  filter(is.na(chip_seconds))
```
We can see that there are only 3 rows with missing chip_times.

Remove missing finish times. This is safe because we only use average finishing times in our model, so individual missing times do not matter. Also there are only 3 total. (KB)
```{r}
marathons_all <- marathons_all %>%
  filter(!is.na(chip_seconds))
```

Labeling Gender as 'male', 'female', or 'unknown', and we decided that nonbinary falls under female. (KB)
```{r}
# Check all unique names under gender
unique(marathons_all$gender)
```
We can see that there are a lot of ways 'male', 'female', 'nonbinary', and 'unknown' are labled.

Make all the genders uniform and standardized (KB)
```{r}
marathons_all <- marathons_all %>%
  mutate(
    gender = tolower(gender),
    gender = case_when(
      gender %in% c("male", "m") ~ "male",
      gender %in% c("female", "f", "w", "x", "nonbinary", "nb") ~ "female",
      TRUE ~ "unknown"
    )
  )

table(marathons_all$gender)
```
We can see that now we only have three genders, `female`, `male`, and `unknown` which consist of 56 rows.  

Remove unknowns since we have only 56 unknowns, and they will not help the model and most likely add noise: (KB)
```{r}
marathons_all <- marathons_all %>% 
  filter(gender != "unknown")

table(marathons_all$gender)
```
We successfully removed the unknowns, leaving us with the desired `female` and `male`. 

Create a variable called winner_time, that consist of the winners or best finishing for that year. Then create a variable called time_ratio (), that consists of chip_seconds / winner_time. (KB)
```{r}
# Add winner_time for each marathon-year-gender
runners <- marathons_all %>%
  group_by(marathon, year, gender) %>%
  mutate(winner_time = min(chip_seconds, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(time_ratio = chip_seconds / winner_time)
```

Create subgroups based on time_ratio. Look at a histogram to adjust the boundaries of the subgroups based on the distribution of the histogram of time_ratio and clear clusters. (KB)
```{r}
runners <- runners %>%
  mutate(
    subgroup = case_when(
      time_ratio <= 1.30 ~ "elite",
      time_ratio > 1.30 & time_ratio <= 1.55 ~ "competitive",
      time_ratio > 1.55 & time_ratio <= 1.80 ~ "average",
      time_ratio > 1.80 & time_ratio <= 2.10 ~ "recreational",
      time_ratio > 2.10 ~ "slow",
      TRUE ~ NA_character_
    ),
    subgroup = factor(subgroup, levels = c("elite", "competitive", "average", "recreational", "slow"))
  )

# Create histogram of ratio_time amongst male and female runners with boundaries for subgroups in red
ggplot(runners, aes(x = time_ratio, fill = gender)) +
  geom_histogram(binwidth = 0.05, position = "dodge") +
  scale_fill_manual(values = c("female" = "deeppink", "male" = "steelblue")) +
  geom_vline(xintercept = c(1.3, 1.55, 1.80, 2.10), linetype = "dashed", color = "red") +
  labs(
    title = "Distribution of Runner Time Ratios to Winner by Gender",
    x = "Time Ratio (Runner / Winner)",
    y = "Count"
  ) +
  theme_minimal()
```
Looking at the histogram of the time_ratio above, we can see that there is a clear clustering in runner-to-winner time ratios and a long right-skewed tail, which helped with the placement of the performance thresholds/ vertical dashed red lines (1.30, 1.55, 1.80, 2.10). We can also see that the distribution for both male and female follow a similar shape, with overall less female relative male runners. Overall, this figure supports the use of ratio-based performance categories by illustrating natural clustering and skewness in marathon finishing times.

Now we can further divide the subgroups created by genders. (KB)
```{r}
runners %>%
  group_by(gender, subgroup) %>%
  summarise(count = n()) %>%
  arrange(gender, subgroup)
```
We can see that the subgroups now have groups for `male` and `female`. We can see that the elite groups both has less runners and male runners have more runners in each group overall. We will leave this as is because these cutoffs are not arbitrary, and they follow the natural shape of the data rather than relying on fixed percentile breaks. Weighting could later be applied; however, it is not initially because subgroup effects are not the primary focus.


Compute average finishing time per subgroup (KB)
```{r}
avg_times <- runners %>%
  group_by(marathon, year, gender, subgroup) %>%
  summarize(
    n = n(),  # number of runners in each subgroup
    avg_chip_seconds = mean(chip_seconds, na.rm = TRUE),  
    .groups = "drop"
  )

avg_times
```
We now have a dataset that contains 1005 rows and 6 columns/ variables. This means that some of the years must be missing for some of the marathon as we know previously when collecting the raw data. Berlin goes from (1996 to 2019), Boston goes from (1996 to 2019), Chicago goes from (1996 to 2023), and NYC goes from (1996 to 2024). Also, after looking through the dataset more, we can see that Berlin is missing data from all female subgroups in 2019 and NYC is missing all male subgroups for 2024. We will leave the data as is because having missing years and genders is not our primary focus, as our focus is on having as much data for finishing/chip times as possible.

Left join weather_clean and airquailty_clean onto the cleaned marathon datasets (KB)
```{r}
final_data <- avg_times %>%
  left_join(weather_clean, by = c("year", "marathon")) %>%
  left_join(airquality_clean, by = c("year", "marathon"))

# move n (number of individuals representing each group) to the first column for neatness
final_data <- final_data %>% 
  select(n, everything())

final_data
str(final_data)
```
We can see that all the datasets were merged into one final_data successfully. We now have a new column `n` that counts the amount of runners in each group for future computations and potential weighing if needed. 

Export final data to csv; undo and add the `#` before and after saving the final_data file (KB)
```{r}
#write_csv(final_data, "merged_marathon_data.csv")
```

